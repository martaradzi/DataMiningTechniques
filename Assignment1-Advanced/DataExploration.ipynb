{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1: Pre-process the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check how many patients/variables there are**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "id\n",
      "AS14.01    21999\n",
      "AS14.02    14581\n",
      "AS14.03    14425\n",
      "AS14.05    15745\n",
      "AS14.06    18092\n",
      "AS14.07    16045\n",
      "AS14.08     7902\n",
      "AS14.09    10886\n",
      "AS14.12    17311\n",
      "AS14.13    19592\n",
      "AS14.14     9286\n",
      "AS14.15     2848\n",
      "AS14.16     3982\n",
      "AS14.17    15826\n",
      "AS14.19    11397\n",
      "AS14.20     3620\n",
      "AS14.23    21852\n",
      "AS14.24    14430\n",
      "AS14.25    12589\n",
      "AS14.26    16403\n",
      "AS14.27    14575\n",
      "AS14.28    19276\n",
      "AS14.29    17499\n",
      "AS14.30    17279\n",
      "AS14.31    11889\n",
      "AS14.32    11193\n",
      "AS14.33    16390\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_mood_smartphone.csv\")\n",
    "counted = df.groupby([\"id\"]).size()\n",
    "print (len(counted))\n",
    "print (counted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "variable\n",
      "activity                22965\n",
      "appCat.builtin          91288\n",
      "appCat.communication    74276\n",
      "appCat.entertainment    27125\n",
      "appCat.finance            939\n",
      "appCat.game               813\n",
      "appCat.office            5642\n",
      "appCat.other             7650\n",
      "appCat.social           19145\n",
      "appCat.travel            2846\n",
      "appCat.unknown            939\n",
      "appCat.utilities         2487\n",
      "appCat.weather            255\n",
      "call                     5239\n",
      "circumplex.arousal       5643\n",
      "circumplex.valence       5643\n",
      "mood                     5641\n",
      "screen                  96578\n",
      "sms                      1798\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counted = df.groupby([\"variable\"]).size()\n",
    "print (len(counted))\n",
    "print (counted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are __***27 patients***__, names from 01 to 33 (some numbers are missing)\n",
    "\n",
    "There are __***19 variables***__\n",
    "\n",
    "\n",
    "\n",
    "**Making individual files for each patient:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RawFile = \"dataset_mood_smartphone.csv\"\n",
    "\n",
    "with open(RawFile) as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    #input_header = reader.next()\n",
    "    for row in reader:\n",
    "        patient = row[1]\n",
    "        CleanedFile = \"./data/\" + patient +\".csv\"\n",
    "        with open(CleanedFile, 'a', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            if row[4] != \"NA\": #deleting rows with NA as VALUE\n",
    "                writer.writerow(row[2:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With good old-fashioned CTRL-F method we discover that: (AND REALIZING YOU DIDN'T NEED TO CHECK THAT CAUSE ITS ALL IN THE ASSIGNMENT DESCRIPTION)\n",
    "\n",
    "activity                Numerical value - use mean\n",
    "\n",
    "appCat.builtin          Time - add times\n",
    "\n",
    "appCat.communication    Time - add times\n",
    "\n",
    "appCat.entertainment    Time - add times\n",
    "\n",
    "appCat.finance          Time - add times\n",
    "\n",
    "appCat.game             Time - add times\n",
    "\n",
    "appCat.office           Time - add times\n",
    "\n",
    "appCat.other            Time - add times\n",
    "\n",
    "appCat.social           Time - add times\n",
    "\n",
    "appCat.travel           Time - add times\n",
    "\n",
    "appCat.unknown          Time - add times\n",
    "\n",
    "appCat.utilities        Time - add times\n",
    "\n",
    "appCat.weather          Time - add times\n",
    "\n",
    "call                    Numerical value - add\n",
    "\n",
    "circumplex.arousal      Numerical value - use mean\n",
    "\n",
    "circumplex.valence      Numerical value - use mean\n",
    "\n",
    "mood                    Numerical value - use mean\n",
    "\n",
    "screen                  Time\n",
    "\n",
    "SMS                     Numerical values - add\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "date\n",
      "2014-02-17      2\n",
      "2014-02-18      1\n",
      "2014-02-19      9\n",
      "2014-02-20      5\n",
      "2014-02-21      1\n",
      "2014-02-22      3\n",
      "2014-02-25      3\n",
      "2014-02-26     15\n",
      "2014-02-27      9\n",
      "2014-02-28      4\n",
      "2014-03-01      1\n",
      "2014-03-03      1\n",
      "2014-03-05      1\n",
      "2014-03-06      1\n",
      "2014-03-07      5\n",
      "2014-03-10      1\n",
      "2014-03-11      3\n",
      "2014-03-12      8\n",
      "2014-03-13      4\n",
      "2014-03-14      4\n",
      "2014-03-15      1\n",
      "2014-03-16      3\n",
      "2014-03-17      1\n",
      "2014-03-18      3\n",
      "2014-03-19      1\n",
      "2014-03-20    113\n",
      "2014-03-21    632\n",
      "2014-03-22    381\n",
      "2014-03-23    368\n",
      "2014-03-24    685\n",
      "             ... \n",
      "2014-04-06    355\n",
      "2014-04-07    467\n",
      "2014-04-08    678\n",
      "2014-04-09    665\n",
      "2014-04-10    387\n",
      "2014-04-11    474\n",
      "2014-04-12    234\n",
      "2014-04-13    191\n",
      "2014-04-14    569\n",
      "2014-04-15    659\n",
      "2014-04-16    553\n",
      "2014-04-17    406\n",
      "2014-04-18    385\n",
      "2014-04-19    363\n",
      "2014-04-20    414\n",
      "2014-04-21    280\n",
      "2014-04-22    732\n",
      "2014-04-23    538\n",
      "2014-04-24    570\n",
      "2014-04-25    520\n",
      "2014-04-26    312\n",
      "2014-04-27    248\n",
      "2014-04-28    392\n",
      "2014-04-29    412\n",
      "2014-04-30    435\n",
      "2014-05-01    751\n",
      "2014-05-02    480\n",
      "2014-05-03    304\n",
      "2014-05-04    272\n",
      "2014-05-05     85\n",
      "Length: 72, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./test_scripts/AS14.01.csv\")\n",
    "counted = df.groupby([\"date\"]).size()\n",
    "print (len(counted))\n",
    "print (counted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         object\n",
       "time         object\n",
       "variable     object\n",
       "value       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./test_scripts/AS14.01.csv\")\n",
    "fsdkjfhsdf = df.drop(['time'], axis=1)\n",
    "\n",
    "testoutpath = \"./data/summary/AS14.01.csv\"\n",
    "fsdkjfhsdf.to_csv(testoutpath, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to creat a table/csv that would summarize each day. Then we can proceed with another algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a day by day summary of the data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables= ['mood', 'circumplex.arousal', 'circumplex.valence', 'activity', 'screen', 'call', 'sms', 'appCat.builtin', 'appCat.communication', 'appCat.entertainment', 'appCat.finance', 'appCat.game', 'appCat.office','appCat.other', 'appCat.social', 'appCat.travel', 'appCat.unknown', 'appCat.utilities', 'appCat.weather']\n",
    "patient = ['01', '02','03','05','06','07','08','09','12','13','14','15','16','17','19','20','23','24','25','26','27','28','29','30','31','32','33']\n",
    "for patientnumber in patient:\n",
    "    inpath = \"./data/AS14.\"+patientnumber+\".csv\"\n",
    "    outpath = \"./data/summary/AS14.\" + patientnumber + \".csv\"\n",
    "\n",
    "    df = pd.read_csv(inpath)\n",
    "\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"]) \n",
    "    #df['date_minus_time'] = df[\"time\"].apply( lambda df : datetime.datetime(year=df.year, month=df.month, day=df.day))\n",
    "    #df.set_index(df[\"date_minus_time\"],inplace=True) # using date as index \n",
    "    df.index = df['time']\n",
    "    df = df.sort_index()\n",
    "\n",
    "\n",
    "    byday = [] #variables summmed/meaned for each day\n",
    "    for i, j in enumerate(variables):\n",
    "        #print(i, j)\n",
    "        dfvariables = df.loc[df['variable'] == j]\n",
    "        if i < 4:\n",
    "            data = dfvariables['value'].resample('D').mean()\n",
    "    #         print(i, j, len(data))\n",
    "    #         print (len(data))\n",
    "        else:\n",
    "            data = dfvariables['value'].resample('D').sum()\n",
    "            #print(i, j, len(data))\n",
    "            #print (len(data))\n",
    "        byday.append(data)\n",
    "\n",
    "    daysSet = pd.concat(byday, axis=1)\n",
    "    daysSet.columns = variables\n",
    "    daysSet= daysSet.replace(0, np.nan)\n",
    "\n",
    "    #print(daysSet)\n",
    "    daysSet.to_csv(outpath, encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DELETE/FILL IN MISSING DATA\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "78",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0ab8c7c97f25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mt2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\marta\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mlookup\u001b[1;34m(self, row_labels, col_labels)\u001b[0m\n\u001b[0;32m   3477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'O'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3479\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\marta\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   2537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2538\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2539\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2540\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 78"
     ]
    }
   ],
   "source": [
    "patientnumber = \"01\"\n",
    "inpath = \"./data/summary/AS14.\" + patientnumber + \".csv\"\n",
    "outpath = \"./data/summary/AS14.\" + patientnumber + \"SSSSSSS.csv\"\n",
    "df = pd.read_csv(inpath)\n",
    "\n",
    "#df.dtypes\n",
    "#print (df) #cheched datatype of each column\n",
    "\n",
    "#df = df.dropna(subset=[\"mood\"], inplace=True) #drops the rows with empty mood\n",
    "        \n",
    "df.dropna(thresh=4, inplace=True)     # drop the rows with at least 4 LEGIT values \n",
    "                                            # GOOD TO START WITH CAUSE THERE IS NO POINT IN FILLING MOOD DATA \n",
    "                                            # WHEN THERE IS NO OTHER DATA IN THAT ROW\n",
    "                                            # MIGHT NEED TO CHANGE TO 3\n",
    "\n",
    "# Most of this is 0 values: \n",
    "# game\n",
    "# office\n",
    "# weather \n",
    "# Probably more accurate to fill it in with 0\n",
    "\n",
    "# Rest - median \n",
    "\n",
    "# s=df.isnull().cumsum()\n",
    "# t1=df[(s==1).shift(-1).fillna(False)].stack().reset_index(level=0,drop=True)\n",
    "# t2=df.lookup(s.idxmax()+1,s.idxmax().index)\n",
    "# df.fillna(t1/(2**s)+t2*(1-0.5**s)*2/2)\n",
    "\n",
    "#df.mood.fillna(method='bfill',inplace=True)  #for back fill - THIS IS CURRENTLY DONE IN THE DATA - This is good for MOOD\n",
    "#df.mood.fillna(method='ffill',inplace=True)  #for forward-fill - THIS IS CURRENTLY DONE IN THE DATA - This is good for MOOD\n",
    "\n",
    "#df.fillna({'game':0, 'office':0, 'weather': 0}, inplace=True) #fill in the empty rows \"call\" and \"sms\" with 0\n",
    "\n",
    "\n",
    "#df.fillna(df.mood.mean(),inplace=True)       # use mean of the data to fill missind data - this not not good for MOOD (too much difference)\n",
    "\n",
    "#df.mood.fillna(df.mood.median(),inplace=True)     # use median to till in missing data - this not not good for MOOD\n",
    "\n",
    "#df = df.fillna(0) #fill in the empty rows with 0\n",
    "#df.fillna({'game':0, 'office':0, 'weather': 0}, inplace=True) #fill in the empty rows \"call\" and \"sms\" with 0\n",
    "\n",
    "\n",
    "print (df)\n",
    "#df.to_csv(outpath, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
