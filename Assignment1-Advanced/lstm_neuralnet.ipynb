{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (Long Short-Term Memory) Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in our dataframe and print the head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   activity  appCat.builtin  appCat.communication  appCat.entertainment  \\\n",
      "0  0.145854       3981.1194            14180.4480             1733.6148   \n",
      "1  0.134836       3763.6968            16751.9910             1513.7718   \n",
      "2  0.138201       4233.9702            21617.1042             1344.1818   \n",
      "3  0.131653       3050.9376            23241.8220             1285.9956   \n",
      "4  0.116179       3349.6764            24425.9784             1613.6046   \n",
      "\n",
      "   appCat.office  appCat.other  appCat.social  appCat.travel  appCat.unknown  \\\n",
      "0       280.7448      293.1720      5245.7394      1567.0596        205.7616   \n",
      "1       179.2272      293.1720      5928.1968      1269.6756        328.8342   \n",
      "2       172.6326      393.6564      6595.2408      1028.1786        442.8642   \n",
      "3       123.5976      308.3046      6645.3762       510.3726        465.1764   \n",
      "4       231.2622      284.5380      6942.8256       516.3780        490.3914   \n",
      "\n",
      "   appCat.utilities  call  circumplex.arousal  circumplex.valence  mood  \\\n",
      "0          687.1332   7.8              0.4750              0.4125  6.65   \n",
      "1          567.7602  13.2              0.5275              0.4050  6.60   \n",
      "2          688.8516  13.8              0.6150              0.3800  6.43   \n",
      "3          349.6182  14.4              0.5950              0.4000  6.51   \n",
      "4          386.4630  13.8              0.5750              0.4150  6.63   \n",
      "\n",
      "   patientno   period        screen  sms  target_mood  \n",
      "0  Patient01  t = 0-5  27878.455201  4.2         6.00  \n",
      "1  Patient01  t = 1-6  28930.917001  3.6         6.75  \n",
      "2  Patient01  t = 2-7  40450.563600  3.6         6.60  \n",
      "3  Patient01  t = 3-8  39517.500001  3.6         7.00  \n",
      "4  Patient01  t = 4-9  46297.493400  3.6         6.40  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/tableX_5.csv')\n",
    "df.fillna(0, inplace = True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data/target into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(df['target_mood'], dtype = float)\n",
    "del df['target_mood']\n",
    "del df['patientno']\n",
    "del df['period']\n",
    "data = np.array(df, dtype = float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show data/target shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 16)\n",
      "(43,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split test/train datasets (set random_state for seeding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 1)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 1)                 72        \n",
      "=================================================================\n",
      "Total params: 72\n",
      "Trainable params: 72\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn = Sequential()\n",
    "rnn.add(LSTM((1), input_shape = (None, 16), return_sequences = False))\n",
    "rnn.compile(loss = 'mean_absolute_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model and save it for re-training/fine-tuning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34 samples, validate on 9 samples\n",
      "Epoch 1/150\n",
      "34/34 [==============================] - 2s 48ms/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "34/34 [==============================] - 0s 164us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      "34/34 [==============================] - 0s 145us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "34/34 [==============================] - 0s 211us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 5/150\n",
      "34/34 [==============================] - 0s 292us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 6/150\n",
      "34/34 [==============================] - 0s 250us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 7/150\n",
      "34/34 [==============================] - 0s 192us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 8/150\n",
      "34/34 [==============================] - 0s 400us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      "34/34 [==============================] - 0s 246us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 10/150\n",
      "34/34 [==============================] - 0s 300us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 11/150\n",
      "34/34 [==============================] - 0s 338us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      "34/34 [==============================] - 0s 431us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 13/150\n",
      "34/34 [==============================] - 0s 221us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      "34/34 [==============================] - 0s 181us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 15/150\n",
      "34/34 [==============================] - 0s 287us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 16/150\n",
      "34/34 [==============================] - 0s 257us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 17/150\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 18/150\n",
      "34/34 [==============================] - 0s 419us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 19/150\n",
      "34/34 [==============================] - 0s 364us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 20/150\n",
      "34/34 [==============================] - 0s 236us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 21/150\n",
      "34/34 [==============================] - 0s 361us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 22/150\n",
      "34/34 [==============================] - 0s 337us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 23/150\n",
      "34/34 [==============================] - 0s 211us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 24/150\n",
      "34/34 [==============================] - 0s 436us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 25/150\n",
      "34/34 [==============================] - 0s 274us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 26/150\n",
      "34/34 [==============================] - 0s 364us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 27/150\n",
      "34/34 [==============================] - 0s 349us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 28/150\n",
      "34/34 [==============================] - 0s 248us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 29/150\n",
      "34/34 [==============================] - 0s 332us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 30/150\n",
      "34/34 [==============================] - 0s 361us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 31/150\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 32/150\n",
      "34/34 [==============================] - 0s 240us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 33/150\n",
      "34/34 [==============================] - 0s 289us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 34/150\n",
      "34/34 [==============================] - 0s 355us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 35/150\n",
      "34/34 [==============================] - 0s 377us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 36/150\n",
      "34/34 [==============================] - 0s 229us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 37/150\n",
      "34/34 [==============================] - 0s 306us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 38/150\n",
      "34/34 [==============================] - 0s 322us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 39/150\n",
      "34/34 [==============================] - 0s 259us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 40/150\n",
      "34/34 [==============================] - 0s 315us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 41/150\n",
      "34/34 [==============================] - 0s 289us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 42/150\n",
      "34/34 [==============================] - 0s 184us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 43/150\n",
      "34/34 [==============================] - 0s 287us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 44/150\n",
      "34/34 [==============================] - 0s 255us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 45/150\n",
      "34/34 [==============================] - 0s 311us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 46/150\n",
      "34/34 [==============================] - 0s 314us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 47/150\n",
      "34/34 [==============================] - 0s 220us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 48/150\n",
      "34/34 [==============================] - 0s 315us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 49/150\n",
      "34/34 [==============================] - 0s 250us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 50/150\n",
      "34/34 [==============================] - 0s 257us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 51/150\n",
      "34/34 [==============================] - 0s 241us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 52/150\n",
      "34/34 [==============================] - 0s 254us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 53/150\n",
      "34/34 [==============================] - 0s 289us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 54/150\n",
      "34/34 [==============================] - 0s 362us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 55/150\n",
      "34/34 [==============================] - 0s 256us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 56/150\n",
      "34/34 [==============================] - 0s 248us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 57/150\n",
      "34/34 [==============================] - 0s 390us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 151us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 59/150\n",
      "34/34 [==============================] - 0s 124us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 60/150\n",
      "34/34 [==============================] - 0s 299us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 61/150\n",
      "34/34 [==============================] - 0s 464us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 62/150\n",
      "34/34 [==============================] - 0s 265us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 63/150\n",
      "34/34 [==============================] - 0s 297us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 64/150\n",
      "34/34 [==============================] - 0s 231us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 65/150\n",
      "34/34 [==============================] - 0s 232us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 66/150\n",
      "34/34 [==============================] - 0s 369us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 67/150\n",
      "34/34 [==============================] - 0s 141us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 68/150\n",
      "34/34 [==============================] - 0s 344us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 69/150\n",
      "34/34 [==============================] - 0s 183us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 70/150\n",
      "34/34 [==============================] - 0s 154us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 71/150\n",
      "34/34 [==============================] - 0s 125us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 72/150\n",
      "34/34 [==============================] - 0s 208us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 73/150\n",
      "34/34 [==============================] - 0s 221us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 74/150\n",
      "34/34 [==============================] - 0s 248us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 75/150\n",
      "34/34 [==============================] - 0s 150us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 76/150\n",
      "34/34 [==============================] - 0s 347us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 77/150\n",
      "34/34 [==============================] - 0s 220us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 78/150\n",
      "34/34 [==============================] - 0s 278us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 79/150\n",
      "34/34 [==============================] - 0s 261us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 80/150\n",
      "34/34 [==============================] - 0s 192us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 81/150\n",
      "34/34 [==============================] - 0s 179us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 82/150\n",
      "34/34 [==============================] - 0s 142us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 83/150\n",
      "34/34 [==============================] - 0s 144us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 84/150\n",
      "34/34 [==============================] - 0s 340us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 85/150\n",
      "34/34 [==============================] - 0s 186us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 86/150\n",
      "34/34 [==============================] - 0s 206us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 87/150\n",
      "34/34 [==============================] - 0s 149us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 88/150\n",
      "34/34 [==============================] - 0s 348us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 89/150\n",
      "34/34 [==============================] - 0s 231us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 90/150\n",
      "34/34 [==============================] - 0s 407us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 91/150\n",
      "34/34 [==============================] - 0s 260us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 92/150\n",
      "34/34 [==============================] - 0s 332us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 93/150\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 94/150\n",
      "34/34 [==============================] - 0s 277us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 95/150\n",
      "34/34 [==============================] - 0s 324us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 96/150\n",
      "34/34 [==============================] - 0s 293us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 97/150\n",
      "34/34 [==============================] - 0s 248us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 98/150\n",
      "34/34 [==============================] - 0s 210us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 99/150\n",
      "34/34 [==============================] - 0s 309us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 100/150\n",
      "34/34 [==============================] - 0s 177us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 101/150\n",
      "34/34 [==============================] - 0s 220us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 102/150\n",
      "34/34 [==============================] - 0s 269us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 103/150\n",
      "34/34 [==============================] - 0s 238us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 104/150\n",
      "34/34 [==============================] - 0s 183us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 105/150\n",
      "34/34 [==============================] - ETA: 0s - loss: 7.1484 - acc: 0.0000e+0 - 0s 233us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 106/150\n",
      "34/34 [==============================] - 0s 315us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 107/150\n",
      "34/34 [==============================] - 0s 360us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 108/150\n",
      "34/34 [==============================] - 0s 298us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 109/150\n",
      "34/34 [==============================] - 0s 304us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 110/150\n",
      "34/34 [==============================] - 0s 141us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 111/150\n",
      "34/34 [==============================] - 0s 286us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 112/150\n",
      "34/34 [==============================] - 0s 372us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 113/150\n",
      "34/34 [==============================] - 0s 220us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 114/150\n",
      "34/34 [==============================] - 0s 192us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 188us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 116/150\n",
      "34/34 [==============================] - 0s 157us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 117/150\n",
      "34/34 [==============================] - 0s 259us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 118/150\n",
      "34/34 [==============================] - 0s 180us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 119/150\n",
      "34/34 [==============================] - 0s 327us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 120/150\n",
      "34/34 [==============================] - 0s 135us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 121/150\n",
      "34/34 [==============================] - 0s 306us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 122/150\n",
      "34/34 [==============================] - 0s 158us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 123/150\n",
      "34/34 [==============================] - 0s 175us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 124/150\n",
      "34/34 [==============================] - 0s 154us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 125/150\n",
      "34/34 [==============================] - 0s 331us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 126/150\n",
      "34/34 [==============================] - 0s 180us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 127/150\n",
      "34/34 [==============================] - 0s 288us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 128/150\n",
      "34/34 [==============================] - 0s 207us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 129/150\n",
      "34/34 [==============================] - 0s 243us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 130/150\n",
      "34/34 [==============================] - 0s 236us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 131/150\n",
      "34/34 [==============================] - 0s 174us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 132/150\n",
      "34/34 [==============================] - 0s 270us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 133/150\n",
      "34/34 [==============================] - 0s 153us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 134/150\n",
      "34/34 [==============================] - 0s 213us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 135/150\n",
      "34/34 [==============================] - 0s 201us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 136/150\n",
      "34/34 [==============================] - 0s 214us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 137/150\n",
      "34/34 [==============================] - 0s 167us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 138/150\n",
      "34/34 [==============================] - 0s 163us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 139/150\n",
      "34/34 [==============================] - 0s 269us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 140/150\n",
      "34/34 [==============================] - 0s 167us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 141/150\n",
      "34/34 [==============================] - 0s 167us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 142/150\n",
      "34/34 [==============================] - 0s 158us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 143/150\n",
      "34/34 [==============================] - 0s 240us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 144/150\n",
      "34/34 [==============================] - 0s 201us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 145/150\n",
      "34/34 [==============================] - 0s 305us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 146/150\n",
      "34/34 [==============================] - 0s 141us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 147/150\n",
      "34/34 [==============================] - 0s 257us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 148/150\n",
      "34/34 [==============================] - 0s 157us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 149/150\n",
      "34/34 [==============================] - 0s 198us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n",
      "Epoch 150/150\n",
      "34/34 [==============================] - 0s 161us/step - loss: 7.1456 - acc: 0.0000e+00 - val_loss: 7.0889 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(x_train, y_train, epochs=150, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict x-test and plot against y-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = rnn.predict(x_test)\n",
    "# print(len(results), len(y_test))\n",
    "\n",
    "############ FIX THIS ############\n",
    "plt.scatter(range(9), results, c='r')\n",
    "plt.scatter(range(9), y_test, c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss from our history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
